output_dir: outputs/runs/agentsafetybench

model:
  provider: openai
  name: gpt-4o
  api_base: https://api.openai.com/v1/chat/completions
  api_key_env: OPENAI_API_KEY
  extra:
    max_new_tokens: 512
    temperature: 0.0

judge_model:
  provider: openai
  name: gpt-4o
  api_base: https://api.openai.com/v1/chat/completions
  api_key_env: OPENAI_API_KEY
  extra:
    max_new_tokens: 512
    temperature: 0.0

# judge_model:
#   provider: huggingface
#   name: "thu-coai/ShieldAgent"    # Taken from the paper
#   max_new_tokens: 256
#   temperature: 0.0
#   api_base: "https://api-inference.huggingface.co/models"
#   api_key_env: "HF_API_TOKEN"
#   extra:
#     max_new_tokens: 256
#     temperature: 0.0

benchmarks:
  agentsafetybench:
    enabled: true

    # data loading
    source: local 
    local_path: /workspaces/agentsafety_data.json
    split: train
    limit: 5                # Small subset for testing

    # agent config
    max_iterations: 3
    tool_choice: local
    max_new_tokens: 512

  agentharm:
    enabled: false

  agentbench:
    enabled: false