
model:
  provider: openai
  name: gpt-4o
  max_new_tokens: 512
  temperature: 0.0
  api_base: https://api.openai.com/v1
  api_key_env: OPENAI_API_KEY
  extra:
    response_format: "json"

judge_model:
  provider: openai
  name: gpt-4o-mini
  max_new_tokens: 512
  temperature: 0.0
  api_base: https://api.openai.com/v1
  api_key_env: OPENAI_API_KEY
  extra:
    response_format: "json"

# judge_model:
#   provider: huggingface
#   name: "thu-coai/ShieldAgent"
#   max_new_tokens: 256
#   temperature: 0.0
#   api_base: "https://api-inference.huggingface.co/models"
#   api_key_env: "HF_API_TOKEN"
#   extra:
#     max_new_tokens: 256
#     temperature: 0.0

refusal_judge_model:
  provider: openai
  name: gpt-4o-2024-08-06

semantic_judge_model:
  provider: openai
  name: gpt-4o-2024-08-06

benchmarks:
  agentbench:
    enabled: True
    task_config: "configs/tasks/knowledgegraph/dev.yaml"
    agent_config: "configs/agents/do_nothing.yaml"
    output_dir: outputs/agentbench/run

  agentsafetybench:
    enabled: False
    source: "local"
    hf_name: "thu-coai/Agent-SafetyBench"
    split: "train"
    limit: 5
    tool_choice: "auto"
    max_iterations: 2

  agentharm:
    enabled: False
    task_name: harmful
    split: test_public
    system_prompt_template: default      # or "llama-3.1"
    prompt_technique: standard           # "cot", "react", "refusal"
    behavior_ids: []
    detailed_behaviors: null
    hint_included: null
    n_irrelevant_tools: 0
    limit: 5
    max_iterations: 3
    tool_choice: auto
    max_new_tokens: 512